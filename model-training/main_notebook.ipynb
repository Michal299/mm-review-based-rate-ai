{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HerbertTokenizer, RobertaModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLMTokenizer'. \n",
      "The class this function is called from is 'HerbertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = HerbertTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")\n",
    "model = RobertaModel.from_pretrained(\"allegro/herbert-klej-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/dataset.csv', sep='$', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_corpus = tokenizer(text=df['user_comment'].tolist(),\n",
    "                            add_special_tokens=True,\n",
    "                            padding='max_length',\n",
    "                            truncation='longest_first',\n",
    "                            max_length=256,\n",
    "                            return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_corpus['input_ids']\n",
    "attention_mask = encoded_corpus['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(input_ids)\n",
    "y = df['user_rate'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4281, 256)\n",
      "(4281,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)\n",
    "train_mask, test_mask, train_mask_y, test_mask_y = train_test_split(attention_mask, y, test_size=0.2, stratify=y, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3424"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=seed)\n",
    "test_mask, valid_mask, _, _ = train_test_split(test_mask, test_mask_y, test_size=0.5, stratify=test_mask_y, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9,  5,  8,  8,  7,  9,  4,  8,  7,  3,  7,  6,  2,  8,  6,  7,\n",
       "        7,  7,  7,  6,  7,  6,  7,  7,  9, 10,  9,  8,  2,  7,  7,  8,  7,\n",
       "        8,  8,  7,  7,  6,  3,  8,  9,  5, 10,  8,  8, 10,  9,  7,  8,  1,\n",
       "        7,  8,  7,  8,  8,  6,  5,  8,  6,  7,  5,  6,  7,  9,  8,  5,  7,\n",
       "        7,  7,  8,  5,  8,  2,  9,  8,  7,  9,  9,  5,  8,  9,  3,  7,  7,\n",
       "        8,  8,  5,  6,  7,  4,  8,  5,  6,  6,  8,  0,  9,  6,  8,  4,  5,\n",
       "        5,  6,  1,  6, 10, 10,  6,  7,  6,  6,  2, 10,  5,  3,  3,  7,  7,\n",
       "        0,  5,  8,  5,  7,  7,  6,  7,  8,  7, 10,  5,  6,  7,  7,  9,  9,\n",
       "        8,  6,  8,  5,  6,  2,  7,  6,  7,  3,  9,  6,  6,  8,  8,  5,  4,\n",
       "        6,  3,  6,  8,  4,  0,  6,  7,  7,  8,  5,  3,  5,  8,  8,  4,  9,\n",
       "        7,  3,  7,  1, 10,  8,  7,  4,  8,  5,  7,  7,  4,  4,  7,  6,  2,\n",
       "        7,  3,  3,  8,  4,  0,  7,  7,  8,  7,  6,  8,  4,  7,  8,  5,  7,\n",
       "        5,  7,  6,  8,  6,  9,  8,  9,  8,  3,  8,  6,  7,  5,  6,  8,  8,\n",
       "        7,  8,  5,  7,  9,  9,  6,  5,  2,  7,  7,  7,  8,  4,  6,  7,  6,\n",
       "       10,  7,  8,  9,  0,  5,  8,  7,  8,  9,  5,  3,  6,  5,  7,  7, 10,\n",
       "        5,  5,  1,  9,  7,  6,  5,  3,  6,  7,  5,  7,  6,  6,  7,  5,  6,\n",
       "        6,  7,  4,  7,  7,  6,  7,  7,  8,  6,  9,  8,  4,  5,  9,  6, 10,\n",
       "        5,  6,  6,  9,  8,  4,  7,  8,  9,  7,  5,  6,  8,  7,  3,  6,  6,\n",
       "        8,  8,  7,  7,  3,  3,  6,  6,  8,  7,  8,  7,  5,  8,  6,  8,  8,\n",
       "        8,  5,  4,  6,  9,  4,  4,  8,  7,  4,  8,  6,  5,  7,  8,  4,  8,\n",
       "        7,  6,  7,  7,  7,  6,  6,  6,  4,  6,  6,  7,  7,  7,  5,  8,  5,\n",
       "        3,  8,  8,  7,  8,  5,  5,  7,  7,  8,  8,  3,  8,  7,  2,  8,  5,\n",
       "        8,  8,  6,  7,  9,  4,  9,  7,  6, 10,  7,  5,  9,  9,  5,  6,  8,\n",
       "        9,  4,  6,  6,  7,  8,  7,  6,  7,  4,  5,  7, 10,  8,  9,  7,  9,\n",
       "        7,  9,  7,  6,  7,  8,  6,  4,  7,  8,  3,  8,  9,  0,  8,  8,  8,\n",
       "        8,  6,  8])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider rescaling the target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataloader(inputs, masks, labels, batch_size):\n",
    "    input_tensor = torch.tensor(inputs)\n",
    "    mask_tensor = torch.tensor(masks)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    dataset = TensorDataset(input_tensor, mask_tensor, labels_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataloader = prepare_dataloader(X_train, train_mask, y_train, 32)\n",
    "validation_dataloader = prepare_dataloader(X_valid, valid_mask, y_valid, 32)\n",
    "train_dataloader = prepare_dataloader(X_test, test_mask, y_test, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
